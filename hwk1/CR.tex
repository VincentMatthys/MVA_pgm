\documentclass[12pt,a4paper,onecolumn]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{amscd}
\usepackage{amsthm}
\usepackage{physics}
\usepackage[left=2.2cm,right=2.2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{textcomp,gensymb} %pour le °C, et textcomp pour éviter les warning
\usepackage{graphicx} %pour les images
\usepackage{caption}
\usepackage{subcaption}
\usepackage[colorlinks=true,
	breaklinks=true,
	citecolor=blue,
	linkcolor=blue,
	urlcolor=blue]{hyperref} % pour insérer des liens
\usepackage{epstopdf} %converting to PDF
\usepackage[export]{adjustbox} %for large figures

\usepackage{array}
\usepackage{dsfont}% indicatrice : \mathds{1}

% -------------------------- Mathematics ---------------------------------------
\usepackage{mathrsfs, amsmath, amsfonts, amssymb}
\usepackage{bm}
\usepackage[Symbol]{upgreek} % For pi \uppi different from /pi
\newcommand{\R}{\mathbb{R}} % For Real space
% ------------------------------------------------------------------------------


% -------------------------- Code format ---------------------------------------
\usepackage[numbered,framed]{matlab-prettifier}
\lstset{
	style              = Matlab-editor,
	basicstyle         = \mlttfamily,
	escapechar         = '',
	mlshowsectionrules = true,
}
% ------------------------------------------------------------------------------

% ------------------------- Blbiographie --------------------------------------
% \usepackage[backend=biber, style=science]{biblatex}
% \addbibresource{biblio.bib}
% ------------------------------------------------------------------------------

% ------------------------- Color table ----------------------------------------
\usepackage{multirow}
% \usepackage[table]{xcolor}
% \definecolor{maroon}{cmyk}{0,0.87,0.68,0.32}/
% ------------------------------------------------------------------------------

\setcounter{tocdepth}{4} %Count paragraph
\setcounter{secnumdepth}{4} %Count paragraph
\usepackage{float}

\usepackage{graphicx} % for graphicspath
% \graphicspath{{../images/}}

\usepackage{array,tabularx}
% \newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
% \newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
% \newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}


% ------------------------------ TITLE -----------------------------------------
\title{Math M2 Probabilistic graphical models 2017/2018}
\author{Vincent Matthys}
% ------------------------------------------------------------------------------

% ------------------------------ NUMEROTATION ----------------------------------
% \renewcommand{\thesubsection}{\alph{subsection}}
% ------------------------------------------------------------------------------


\begin{document}
\begin{tabularx}{0.8\textwidth}{@{} l X r @{} }
	{\textsc{Master MVA}}                   &  & \textsc{Homework 1} \\
	\textsc{Probabilistic graphical models} &  & {Vincent Matthys}   \\
\end{tabularx}
\vspace{1.5cm}
\begin{center}
	\rule[11pt]{5cm}{0.5pt}

	\textbf{\LARGE \textsc{Compte-rendu du devoir 1}}
	\vspace{0.5cm}\\
	Vincent Matthys\\
	\rule{5cm}{0.5pt}
	\vspace{1.5cm}
\end{center}

\section{Leaning in discrete graphical models}

Etant donné que \(z\) et \(x\) sont des variables à valeurs discrètes prenant respectivement \(M\) et \(K\) valeurs, on peut procéder au \textit{one hot encoding}, notant respectivement \(\bm{Z}\) et \(\bm{X}\) leur encodage sur, respectivement \(\R^M\) et \(\R^K\). Ainsi, on peut écrire :

\[
	p(z = m) = P(Z_m = 1) = \pi_m
\]
\[
	p(x = k | z = m) = p(X_k = 1 | Z_m = 1) = \theta_{mk}
\]
En supposant que l'on ait un échantillon de \(n\) observations de \((x, z)\), on peut exprimer la probabilité jointe d'une obersvation \(i\) :

\begin{equation}
	\begin{split}
		p(x^{(i)}, z^{(i)} ; \bm{\pi}, \bm{\theta}) & = p(z^{(i)} ; \bm{\pi}) p(x^{(i)} | z^{(i)} ; \bm{\theta})                                          \\
		p(x^{(i)}, z^{(i)} ; \bm{\pi}, \bm{\theta}) & = \prod_{m=1}^M \prod_{k=1}^K \theta_{mk}^{X_k^{(i)} Z_m^{(i)}} \prod_{l = 1}^M\pi_l^{Z_l^{(i)}}
	\end{split}
	\label{1_joint}
\end{equation}

On peut alors écrire la log-vraisemblance de l'échantillon dans le modèle \(( \bm{\pi}, \bm{\theta})\), composé d'observations i.i.d., en utilisant~\eqref{1_joint}:

\begin{equation}
	\begin{split}
		\ell( \bm{\pi}, \bm{\theta}) & = \sum_{i = 1}^n \ln(p(x^{(i)}, z^{(i)} ; \bm{\pi}, \bm{\theta}))                                                                        \\
		& = \sum_{i = 1}^n\left(\ln\left(\prod_{m=1}^M \prod_{k=1}^K \theta_{mk}^{X_k^{(i)} Z_m^{(i)}} \prod_{l = 1}^M\pi_l^{Z_l^{(i)}}\right)\right)                   \\
		& = \sum_{i = 1}^n\left(\sum_{m=1}^M \sum_{k=1}^K \ln(\theta_{mk}^{X_k^{(i)} Z_m^{(i)}}) + \sum_{l = 1}^M\ln(\pi_l^{Z_l^{(i)}})\right)                          \\
		& = \sum_{i = 1}^n\left(\sum_{m=1}^M \sum_{k=1}^K X_k^{(i)} Z_m^{(i)}\ln(\theta_{mk}) + \sum_{l = 1}^M {Z_l^{(i)}}\ln(\pi_l)\right)                             \\
		& = \sum_{m=1}^M \sum_{k=1}^K \left(\sum_{i = 1}^n X_k^{(i)} Z_m^{(i)}\right)\ln(\theta_{mk}) + \sum_{l = 1}^M\left(\sum_{i = 1}^n {Z_l^{(i)}}\right)\ln(\pi_l) \\
		& = \sum_{m=1}^M \sum_{k=1}^K \alpha_{mk}\ln(\theta_{mk}) + \sum_{l = 1}^M \beta_l\ln(\pi_l)
	\end{split}
	\label{1_logl}
\end{equation}

avec
\begin{align*}
	\alpha_{mk} & = \sum_{i = 1}^n X_k^{(i)} Z_m^{(i)} \\
	\beta_l     & = \sum_{i = 1}^n {Z_l^{(i)}}
\end{align*}

D'après~\eqref{1_logl}, la log-vraisemblance est donc strictement concave en chaque composantes de \(\bm{\pi}\) et \(\bm{\theta}\), par combinaison linéaire de logarithmes. D'autre part, on a les contraintes linéaires suivantes :
\begin{equation}
	\begin{split}
		\sum_{m = 1}^M \pi_m - 1 &= 0\\
		\sum_{k = 1}^K \theta_{mk} - 1 &= 0 \,,  \forall m : 1..M
	\end{split}
\end{equation}

On peut donc écrire le Lagrangien, en utilisant les multiplicateurs de Lagrange correspondants, associé au problème de maximisation de la log-vraisemblance~\eqref{1_logl} :

\begin{equation}
	\mathcal{L}(\bm{\pi}, \bm{\theta}, \lambda, \bm{\gamma}) = \sum_{m=1}^M \sum_{k=1}^K \alpha_{mk}\ln(\theta_{mk}) + \sum_{l = 1}^M \beta_l\ln(\pi_l) - \lambda\left(\sum_{m = 1}^K \pi_m - 1\right) - \bm{\gamma}^\intercal \begin{pmatrix}
		\vdots                         \\
		\sum_{k = 1}^K \theta_{mk} - 1 \\
		\vdots
	\end{pmatrix}
	\label{1_lagrang}
\end{equation}

Le problème admet une solution unique, notée \( (\bm{\widehat{\pi_{MLE}}}, \bm{\widehat{\theta_{MLE}}}) \) que l'on trouve par dérivation de~\eqref{1_lagrang}

\subsection{Par rapport à \protect\(\pi_m\)}

\[
	\frac{\partial \mathcal{L}(\bm{\pi}, \bm{\theta}, \lambda, \bm{\gamma})}{\partial \pi_m} = \frac{\beta_m}{\pi_m} - \lambda = 0
	\implies \pi_m \propto \beta_m
	\implies \pi_m = \frac{\beta_m}{\sum_{m=1}^M \beta_m}= \frac{\sum_{i = 1}^n {Z_m^{(i)}}}{\sum_{m=1}^M \sum_{i = 1}^n {Z_m^{(i)}}}
\]
D'où finalement :
\begin{equation}
	\left(\widehat{\pi_{MLE}}\right)_m = \frac{1}{n} \sum_{i = 1}^n {Z_m^{(i)}}
	\label{1_pi}
\end{equation}

\subsection{Par rapport à \protect\(\theta_{mk}\)}

\[
	\frac{\partial \mathcal{L}(\bm{\pi}, \bm{\theta}, \lambda, \bm{\gamma})}{\partial \theta_{mk}} = \frac{\alpha_{mk}}{\theta_{mk}} - \gamma_m = 0 \implies \theta_{mk} \propto \alpha_{mk}
	\implies \theta_{mk} = \frac{\alpha_{mk}}{\sum_{k = 1}^K \alpha_{mk}} = \frac{\sum_{i = 1}^n X_k^{(i)} Z_m^{(i)}}{\sum_{i = 1}^n \left(\sum_{k=1}^K X_k^{(i)}\right) Z_m^{(i)}}
\]

D'où finalement :

\begin{equation}
	\left( \widehat{{\theta_{MLE}}} \right)_{mk} = \frac{\sum_{i = 1}^n X_k^{(i)} Z_m^{(i)}}{\sum_{i = 1}^n Z_m^{(i)}}
\end{equation}

On remarque que si \( \sum_{i = 1}^n Z_m^{(i)} \) est nulle, alors \( \left(\widehat{{\theta_{MLE}}}\right)_{mk} \) n'est pas défini, et ce pour tout \( k\). Mais, dans de telles conditions, cela signifie que la \( m \)\up{ième} valeur de \( z \) n'a pas été observée, et donc que l'on peut réduire \( \bm{\theta} \) d'une ligne entière, puisqu'alors la probabilité d'observer une quelconque valeur de \( x\) sachant que \( z\) prend la valeur \( m\) est nulle.

En définitif, on peut s'affranchir de l'hypothèse implicite qu'aucune composante de \(\bm{\pi}\) ni de \(\bm{\theta}\) n'est nulle. En effet, si tel est le cas, alors la probabilité d'observer une telle observation est nulle.

\subsection{Conclusion}
On remarque donc que l'estimateur de \(\bm{\pi}\) n'est rien d'autre que la moyenne empirique des observations de \( z\), et que l'estimateur de \(\bm{\theta}\) est également la moyenne des observations de \( x\) pour une valeur de \( z \) donnée.

\section{Linear classification}

\subsection{Generative model : Linear Discriminant Analysis}

Supposons un échantillon de \( N \) observations de \( x, y \), notées, \( (x_n, y_n) \), pour \( n \) variant de \( 1 \) à \( N \), où \(y_n \in \{0,1\} \). Etant donné le modèle suivant :
\begin{equation*}
	\begin{split}
		y &\sim Bernoulli(\uppi) \\
		p(x | y = i) &= \frac{1}{2\pi\sqrt{\det\Sigma}}\exp\left(-\frac{1}{2}(x - \mu_i)^\intercal\Sigma^{-1}(x - \mu_i)\right)
	\end{split}
\end{equation*}
paramétré par :
\[
	\Theta = (\mu_0, \mu_1, \Sigma, \uppi)
\]
on peut réecrire la probabilité d'observer \( (x_n, y_n )\) sous la forme comprenant déjà la contrainte sur \( \pi \):
\begin{equation}
	p(x_n, y_n) = \left(\uppi p(x_n | y_n = 1)\right)^{y_n} \left((1 - \uppi) p(x_n | y_n = 0)\right)^{1 - y_n}
	\label{2_1_joint}
\end{equation}
ce qui permet de déterminer la log-vraisemblance de l'échantillon composé de \( N \) observations i.i.d dans le modèle \( \Theta \) en utilisant~\eqref{2_1_joint} :
\begin{equation}
	\begin{split}
		\ell(\Theta) & =  \sum_{n = 1}^N \ln(p(x_n, y_n ; \Theta)) \\
		\ell(\Theta) & =  \sum_{n = 1}^N \ln\left(\left(\uppi p(x_n | y_n = 1)\right)^{y_n} \left((1 - \uppi) p(x_n | y_n = 0)\right)^{1 - y_n}\right) \\
		\ell(\Theta) & =  \sum_{n = 1}^N
		\left(y_n \left(\ln
			\left(\frac{\uppi}{2\pi\sqrt{\det\Sigma}}\right) -\frac{1}{2}(x_n - \mu_1)^\intercal\Sigma^{-1}(x_n - \mu_1) \right)\right)\\
		&+ 	\sum_{n = 1}^N\left((1 - y_n)
		\left(\ln
		\left(\frac{1 - \uppi}{2\pi\sqrt{\det\Sigma}}\right) -\frac{1}{2}(x_n - \mu_0)^\intercal\Sigma^{-1}(x_n - \mu_0) \right)\right) \\
		\ell(\Theta) & =  \sum_{n = 1}^N
		\left(y_n \left(\ln
			\uppi - \ln(2\pi) -\frac{1}{2}\ln\det\Sigma -\frac{1}{2}(x_n - \mu_1)^\intercal\Sigma^{-1}(x_n - \mu_1) \right)\right)\\
		&+ 	\sum_{n = 1}^N\left((1 - y_n)
		\left(\ln(1 - \uppi) - \ln(2\pi) -\frac{1}{2}\ln\det\Sigma -\frac{1}{2}(x_n - \mu_0)^\intercal\Sigma^{-1}(x_n - \mu_0) \right)\right)\\
	\end{split}
	\label{2_1_logl}
\end{equation}

\( \ell(\Theta) \) est donc une fonction stricement concave en \( \uppi\) par stricte concavité du logarithme, en \( \mu_0 \) et \( \mu_1 \) par stricte concavité de l'opposé d'une forme quadratique (avec les valeurs propres de  \( \Sigma \) strictement positives), et en \( \Sigma \) par convextié du logdet.
Le problème de maximisation \( \ell(\Theta) \) admet une solution unique, notée \( (\widehat{\mu_{0, MLE}}, \widehat{\mu_{1, MLE}}, \widehat{\Sigma_{MLE}}, \widehat{\uppi_{MLE}}) \) que l'on trouve par dérivation de~\eqref{2_1_logl}.

\subsubsection{Calcul du MLE}
\paragraph*{Par rapport à \protect \(\uppi \)}

\[
	\frac{\partial \ell(\mu_0, \mu_1, \Sigma, \uppi)}{\partial \uppi} = 	\sum_{n = 1}^N\left( \frac{y_n}{\uppi} - \frac{1 - y_n}{1 - \uppi} \right) = 0
	\implies \frac{1- \uppi}{\uppi} = \frac{\sum_{n = 1}^N (1 - y_n)}{\sum_{n = 1}^N y_n}
	\implies \uppi = \frac{\sum_{n = 1}^N y_n}{\sum_{n = 1}^N 1}
\]
D'où finalement :
\begin{equation}
	\left(\widehat{\uppi_{MLE}}\right) = \frac{1}{N}\sum_{n = 1}^N y_n
	\label{2_1_pi}
\end{equation}
qui est la moyenne empirique des classes observées.

\paragraph*{Par rapport à \protect \(\mu_0 \) et \protect \(\mu_1 \)}
\[
	\frac{\partial \ell(\mu_0, \mu_1, \Sigma, \uppi)}{\partial \mu_0} = 	\sum_{n = 1}^N\left((1 - y_n)(- \Sigma^{-1}(x_n - \mu_0)) \right) = 0
	\implies \mu_0 = \frac{\sum_{n = 1}^N (1 - y_n)x_n}{\sum_{n = 1}^N (1 - y_n)}
\]
En introduisant \( A = \sum_{n = 1}^N y_n\), on a donc :
\begin{equation}
	\left(\widehat{\mu_{0,MLE}}\right) = \frac{1}{N - A}\sum_{y_n =\,0} x_n
	\label{2_1_mu0}
\end{equation}
Et de la même façon :
\begin{equation}
	\left(\widehat{\mu_{1,MLE}}\right) = \frac{1}{A}\sum_{y_n =\,1} x_n
	\label{2_1_mu1}
\end{equation}

\paragraph*{Par rapport à \protect\( \Sigma\)}
En introduisant temporairement \( \Lambda = \Sigma^{-1}\), la log-vraisemblance se réecrit :

\begin{equation}
	\begin{split}
		\ell(\Theta) & =  \sum_{n = 1}^N
		\left(y_n \left(\ln
			\uppi - \ln(2\pi) + \frac{1}{2}\ln\det\Lambda -\frac{1}{2}(x_n - \mu_1)^\intercal\Lambda(x_n - \mu_1) \right)\right)\\
		&+ 	\sum_{n = 1}^N\left((1 - y_n)
		\left(\ln(1 - \uppi) - \ln(2\pi) + \frac{1}{2}\ln\det\Lambda -\frac{1}{2}(x_n - \mu_0)^\intercal\Lambda(x_n - \mu_0) \right)\right)
	\end{split}
	\label{2_1_lambda_l}
\end{equation}

En introduisant aussi :
\begin{equation}
	\begin{split}
		\widetilde \Sigma_0 &= \frac{1}{N - A}\sum_{y_n = 0} (x_n - \mu_0)^\intercal(x_n - \mu_0) \\
		\widetilde \Sigma_1 &= \frac{1}{A}\sum_{y_n = 1} (x_n - \mu_1)^\intercal(x_n - \mu_1)
	\end{split}
\end{equation}

On peut réecrire~\eqref{2_1_lambda_l} sous la forme suivante :
\begin{equation}
	\begin{split}
		\ell(\Theta) & = -N\ln(2\pi) + A\ln\uppi + (N - A)\ln(1 - \uppi) + \frac{N}{2}\ln\det\Lambda - \frac{N - A}{2}\tr(\widetilde \Sigma_0 \Lambda) -\frac{A}{2}\tr(\widetilde \Sigma_1 \Lambda)\\
		\label{2_1_lambda_trace_l}
	\end{split}
\end{equation}

Dérivant~\eqref{2_1_lambda_trace_l} par rapport à \( \Lambda\) :

\[
	\frac{\partial \ell(\mu_0, \mu_1, \Lambda, \uppi)}{\partial \Lambda} = \frac{N}{2}\Lambda^{-1} - \frac{N - A}{2}\widetilde \Sigma_0 - \frac{A}{2}\widetilde \Sigma_1= 0
	\implies \Lambda^{-1} = \frac{1}{N}\left((N - A)\widetilde \Sigma_0 + A\widetilde \Sigma_1\right)
\]
D'où finalement :
\begin{equation}
	\widehat{\Sigma_{MLE}} = \frac{1}{N}\left((N - A)\widetilde \Sigma_0 + A\widetilde \Sigma_1\right)
\end{equation}


\subsubsection{Comparaison avec la régression logistique}

Le modèle d'une régression logistique repose sur un modèle \( (\bm{\omega}, \bm{b})\) tel que :
\begin{equation}
	p(y = 1 | x) = \sigma(\bm{\omega}^\intercal x + \bm{b})
\end{equation}

Dans le cas du \textit{LDA}, on peut également calculer cette probabilité comme suit :
\begin{equation}
	\begin{split}
		p(y = 1 | x) &= \frac{p(x | y = 1)p(y = 1)}{p(x)} \\
		&= \frac{p(x | y = 1)p(y = 1)}{p(x | y = 0)p(y = 0) + p(x | y = 1)p(y = 1)} \\
		&= 1 / \left(1 + \frac{p(x | y = 0)p(y = 0)}{p(x | y = 1)p(y = 1)}\right)\\
		&= 1 / \left(1 + \frac{1 - \uppi}{\uppi}\exp\left(-\frac{1}{2}(x - \mu_0)^\intercal\Sigma^{-1}(x - \mu_0) + \frac{1}{2}(x - \mu_1)^\intercal\Sigma^{-1}(x - \mu_1)\right)\right)\\
		&= \sigma\left(-\ln(\frac{1 - \uppi}{\uppi}) - \frac{1}{2}Q(\mu_0, \mu_1, \Sigma^{-1}, x)\right)
	\end{split}
	\label{2_1_LDA1}
\end{equation}
Où :
\begin{equation*}
	\begin{split}
		Q(\mu_0, \mu_1, \Sigma^{-1}, x) &= -(x - \mu_0)^\intercal\Sigma^{-1}(x - \mu_0) + (x - \mu_1)^\intercal\Sigma^{-1}(x - \mu_1)\\
		Q(\mu_0, \mu_1, \Sigma^{-1}, x) &= -x^\intercal\Sigma^{-1}x + \mu_0^\intercal\Sigma^{-1}x + x^\intercal\Sigma^{-1}\mu_0 - \mu_0^\intercal\Sigma^{-1}\mu_0\\
		&+ x^\intercal\Sigma^{-1}x - \mu_1^\intercal\Sigma^{-1}x - x^\intercal\Sigma^{-1}\mu_1 + \mu_1^\intercal\Sigma^{-1}\mu_1 \\
		Q(\mu_0, \mu_1, \Sigma^{-1}, x) &= 2(\mu_0 - \mu_1)^\intercal\Sigma^{-1}x + \mu_1^\intercal\Sigma^{-1}\mu_1 - \mu_0^\intercal\Sigma^{-1}\mu_0\\
	\end{split}
\end{equation*}

Ainsi, le terme quadratique disparaît sous l'hyopthèse de l'égalité des matrices de covariance entre les deux gaussiennes, d'où le L de LDA, et on peut écrire~\eqref{2_1_LDA1} sous la forme :
\begin{equation}
	\begin{split}
		p(y = 1 | x) &= \sigma\left((\mu_1 - \mu_0)^\intercal\Sigma^{-1}x + \mu_0^\intercal\Sigma^{-1}\mu_0 - \mu_1^\intercal\Sigma^{-1}\mu_1 - \ln(\frac{1 - \uppi}{\uppi}))\right) \\
		p(y = 1 | x) &= \sigma\left(\bm{\omega_{LDA}}^\intercal x + \bm{b_{LDA}}\right)
	\end{split}
\end{equation}
Où :
\begin{equation}
	\begin{split}
		\bm{\omega_{LDA}} & = \Sigma^{-1} (\mu_1 - \mu_0)\\
		\bm{b_{LDA}} &= \mu_0^\intercal\Sigma^{-1}\mu_0 - \mu_1^\intercal\Sigma^{-1}\mu_1 - \ln(\frac{1 - \uppi}{\uppi})
	\end{split}
\end{equation}
La LDA est donc équivalent à une régression logistique les paramètres \((\bm{\omega_{LDA}}, \bm{b_{LDA}}) \)

\end{document}
